{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joseasd213/Gatos-y-Perros/blob/main/Perro_vs_gato_xd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_nqWOIj8BkZ",
        "outputId": "e51c1dcd-56d7-469c-ca41-83d1872fd6a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 90ms/step - accuracy: 0.5027 - loss: 0.6972 - val_accuracy: 0.6390 - val_loss: 0.6674\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.6463 - loss: 0.6356 - val_accuracy: 0.6500 - val_loss: 0.6239\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.7379 - loss: 0.5509 - val_accuracy: 0.5960 - val_loss: 0.7248\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.7795 - loss: 0.4649 - val_accuracy: 0.6290 - val_loss: 0.7590\n",
            "Epoch 5/5\n",
            "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8260 - loss: 0.3770"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import pathlib\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Descargar y preparar el dataset\n",
        "url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_path = tf.keras.utils.get_file('cats_and_dogs_filtered.zip', origin=url)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.dirname(zip_path))\n",
        "\n",
        "base_dir = os.path.join(pathlib.Path(zip_path).parent, 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(100, 100),\n",
        "    batch_size=10,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(100, 100),\n",
        "    batch_size=10,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Definir el modelo CNN\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(8, (3,3), activation='relu', input_shape=(100, 100, 3)),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(16, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilación del modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,  # Puedes cambiarlo si quieres entrenar más\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "# Gráfica de precisión\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Entrenamiento')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validación')\n",
        "plt.title('Precisión del modelo')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Guardar el modelo\n",
        "model_json = model.to_json()\n",
        "with open(\"model_gats_gossos.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"model_gats_gossos.weights.h5\")\n",
        "\n",
        "# Descargar los archivos del modelo\n",
        "from google.colab import files\n",
        "files.download(\"model_gats_gossos.json\")\n",
        "files.download(\"model_gats_gossos.weights.h5\")\n",
        "\n",
        "# Subir una imagen para predecir\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Predecir con la imagen subida\n",
        "from PIL import Image\n",
        "image_name = list(uploaded.keys())[0]  # Obtiene el nombre de la imagen subida\n",
        "\n",
        "# Preparar la imagen\n",
        "image = Image.open(image_name).convert(\"RGB\").resize((100, 100))\n",
        "image_array = np.array(image) / 255.0\n",
        "image_array = np.expand_dims(image_array, axis=0)  # Añadir dimensión batch\n",
        "\n",
        "# Hacer la predicción\n",
        "prediction = model.predict(image_array)\n",
        "prob = float(prediction[0])\n",
        "\n",
        "# Mostrar el resultado de la predicción\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "if prob > 0.5:\n",
        "    pred_label = f\"🐶 ¡Es un *perro*! ({prob*100:.2f}%)\"\n",
        "    pred_clase = \"perro\"\n",
        "else:\n",
        "    pred_label = f\"🐱 ¡Es un *gato*! ({(1 - prob)*100:.2f}%)\"\n",
        "    pred_clase = \"gato\"\n",
        "plt.title(pred_label)\n",
        "plt.show()\n",
        "\n",
        "# Pedir retroalimentación al usuario\n",
        "print(f\"La IA predijo que es un {pred_clase}.\")\n",
        "feedback = input(\"¿Es correcta la predicción? (sí / no / dime cuál es): \").strip().lower()\n",
        "\n",
        "if feedback == \"si\":\n",
        "    print(\"✅ ¡Genial! Me alegra haber acertado. 😺🐶\")\n",
        "elif feedback == \"no\":\n",
        "    print(\"❌ Gracias por avisarme. ¿Qué es realmente? (escribe 'gato' o 'perro')\")\n",
        "    correcion = input(\"Tu respuesta: \").strip().lower()\n",
        "    if correcion == \"gato\" or correcion == \"perro\":\n",
        "        print(f\"✅ Gracias por corregirme. He anotado que es un {correcion}.\")\n",
        "    else:\n",
        "        print(\"⚠️ No entendí tu respuesta, pero gracias por intentarlo.\")\n",
        "else:\n",
        "    print(\"🤔 No entendí tu respuesta, pero gracias por participar.\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjc+DhQcO8vVKqUPMGy2c7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}